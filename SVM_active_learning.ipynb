{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jn1SRYoENRN",
        "outputId": "3f94f60f-2343-424f-88a7-81625f9a44b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.6)\n",
            "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
            "                  name     role         type demographic description units  \\\n",
            "0                   ID       ID  Categorical        None        None  None   \n",
            "1            Diagnosis   Target  Categorical        None        None  None   \n",
            "2              radius1  Feature   Continuous        None        None  None   \n",
            "3             texture1  Feature   Continuous        None        None  None   \n",
            "4           perimeter1  Feature   Continuous        None        None  None   \n",
            "5                area1  Feature   Continuous        None        None  None   \n",
            "6          smoothness1  Feature   Continuous        None        None  None   \n",
            "7         compactness1  Feature   Continuous        None        None  None   \n",
            "8           concavity1  Feature   Continuous        None        None  None   \n",
            "9      concave_points1  Feature   Continuous        None        None  None   \n",
            "10           symmetry1  Feature   Continuous        None        None  None   \n",
            "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
            "12             radius2  Feature   Continuous        None        None  None   \n",
            "13            texture2  Feature   Continuous        None        None  None   \n",
            "14          perimeter2  Feature   Continuous        None        None  None   \n",
            "15               area2  Feature   Continuous        None        None  None   \n",
            "16         smoothness2  Feature   Continuous        None        None  None   \n",
            "17        compactness2  Feature   Continuous        None        None  None   \n",
            "18          concavity2  Feature   Continuous        None        None  None   \n",
            "19     concave_points2  Feature   Continuous        None        None  None   \n",
            "20           symmetry2  Feature   Continuous        None        None  None   \n",
            "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
            "22             radius3  Feature   Continuous        None        None  None   \n",
            "23            texture3  Feature   Continuous        None        None  None   \n",
            "24          perimeter3  Feature   Continuous        None        None  None   \n",
            "25               area3  Feature   Continuous        None        None  None   \n",
            "26         smoothness3  Feature   Continuous        None        None  None   \n",
            "27        compactness3  Feature   Continuous        None        None  None   \n",
            "28          concavity3  Feature   Continuous        None        None  None   \n",
            "29     concave_points3  Feature   Continuous        None        None  None   \n",
            "30           symmetry3  Feature   Continuous        None        None  None   \n",
            "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n",
            "15             no  \n",
            "16             no  \n",
            "17             no  \n",
            "18             no  \n",
            "19             no  \n",
            "20             no  \n",
            "21             no  \n",
            "22             no  \n",
            "23             no  \n",
            "24             no  \n",
            "25             no  \n",
            "26             no  \n",
            "27             no  \n",
            "28             no  \n",
            "29             no  \n",
            "30             no  \n",
            "31             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "\n",
        "# metadata\n",
        "print(breast_cancer_wisconsin_diagnostic.metadata)\n",
        "\n",
        "# variable information\n",
        "print(breast_cancer_wisconsin_diagnostic.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgdUY-essBMr"
      },
      "outputs": [],
      "source": [
        "# import the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G840hzKr1SN",
        "outputId": "4447b124-0a94-438b-a71d-ab3697a82ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (455, 30)\n",
            "X_test shape: (114, 30)\n",
            "y_train shape: (455, 1)\n",
            "y_test shape: (114, 1)\n",
            "     Diagnosis\n",
            "0            1\n",
            "1            1\n",
            "2            1\n",
            "3            1\n",
            "4            1\n",
            "..         ...\n",
            "564          1\n",
            "565          1\n",
            "566          1\n",
            "567          1\n",
            "568          0\n",
            "\n",
            "[569 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "# helper function to split the data\n",
        "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    # determine the type of the dataset\n",
        "    is_pandas = isinstance(X, pd.DataFrame)\n",
        "\n",
        "    # shuffle the indices\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # split indices\n",
        "    split_idx = int(len(indices) * (1 - test_size))\n",
        "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
        "\n",
        "    # split the data\n",
        "    if is_pandas:\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    else:\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73M6iFbXtTQk",
        "outputId": "009a418d-33cc-4613-d0e1-763dfe55e841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original X_train mean: radius1                14.053226\n",
            "texture1               19.311341\n",
            "perimeter1             91.496571\n",
            "area1                 647.105055\n",
            "smoothness1             0.096316\n",
            "compactness1            0.104691\n",
            "concavity1              0.088904\n",
            "concave_points1         0.048606\n",
            "symmetry1               0.181284\n",
            "fractal_dimension1      0.062977\n",
            "radius2                 0.398979\n",
            "texture2                1.232834\n",
            "perimeter2              2.828935\n",
            "area2                  38.947615\n",
            "smoothness2             0.007021\n",
            "compactness2            0.025552\n",
            "concavity2              0.032247\n",
            "concave_points2         0.011661\n",
            "symmetry2               0.020617\n",
            "fractal_dimension2      0.003799\n",
            "radius3                16.203837\n",
            "texture3               25.737363\n",
            "perimeter3            106.930593\n",
            "area3                 872.951429\n",
            "smoothness3             0.132254\n",
            "compactness3            0.254927\n",
            "concavity3              0.272903\n",
            "concave_points3         0.113689\n",
            "symmetry3               0.291066\n",
            "fractal_dimension3      0.084074\n",
            "dtype: float64\n",
            "Scaled X_train mean: radius1               1.834918e-16\n",
            "texture1              3.025663e-16\n",
            "perimeter1            2.342449e-17\n",
            "area1                -2.498612e-16\n",
            "smoothness1           3.064704e-16\n",
            "compactness1          2.615734e-16\n",
            "concavity1            5.075305e-17\n",
            "concave_points1       1.141944e-16\n",
            "symmetry1             7.886244e-16\n",
            "fractal_dimension1    1.214169e-15\n",
            "radius2               1.971561e-16\n",
            "texture2             -3.269668e-17\n",
            "perimeter2           -1.307867e-16\n",
            "area2                -1.229786e-16\n",
            "smoothness2           2.147245e-16\n",
            "compactness2         -7.417754e-17\n",
            "concavity2            9.760202e-17\n",
            "concave_points2      -1.015061e-16\n",
            "symmetry2            -2.342449e-16\n",
            "fractal_dimension2    5.563315e-17\n",
            "radius3               1.366428e-16\n",
            "texture3              1.356668e-16\n",
            "perimeter3            1.210265e-16\n",
            "area3                -1.405469e-16\n",
            "smoothness3          -1.717796e-16\n",
            "compactness3          2.928061e-17\n",
            "concavity3           -7.320152e-17\n",
            "concave_points3       5.856121e-17\n",
            "symmetry3             5.465713e-17\n",
            "fractal_dimension3    6.832142e-16\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# helper function to standardize the data\n",
        "def standard_scaler(X_train, X_test):\n",
        "  mean = np.mean(X_train, axis=0)\n",
        "  std = np.std(X_train, axis=0)\n",
        "\n",
        "  # avoid division by zero in case of zero variance\n",
        "  std = np.where(std == 0, 1, std)\n",
        "\n",
        "  # perform scaling\n",
        "  X_train_scaled = (X_train - mean) / std\n",
        "  X_test_scaled = (X_test - mean) / std\n",
        "\n",
        "  return X_train_scaled, X_test_scaled\n",
        "\n",
        "\n",
        "\n",
        "X_train_scaled, X_test_scaled = standard_scaler(X_train, X_test)\n",
        "print(\"Original X_train mean:\", np.mean(X_train, axis=0))\n",
        "print(\"Scaled X_train mean:\", np.mean(X_train_scaled, axis=0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "utilize package sklearn and evluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivm3Ie_slDgD",
        "outputId": "c92b6b63-8b77-4048-d3f2-28abd625030d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9824561403508771\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.97      1.00      0.99        71\n",
            "           M       1.00      0.95      0.98        43\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# It's good practice to scale features before feeding them to SVM\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the classifier with default parameters\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "# Make predictions\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Locae7oy5TTI",
        "outputId": "1d1041f4-2783-4e24-89df-ef3f7b432158"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validated Accuracy: 0.9771619313771154\n",
            "Cross-Validated F1 Score: 0.9753836264480608\n",
            "Cross-Validated Recall: 0.9731786715122779\n",
            "Test Accuracy: 0.9824561403508771\n",
            "Test F1 Score: 0.9811507936507937\n",
            "Test Recall: 0.9767441860465116\n",
            "ROC AUC Score: 0.99737962659679\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.97      1.00      0.99        71\n",
            "           M       1.00      0.95      0.98        43\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline that includes scaling and the classifier\n",
        "svm_pipeline = make_pipeline(StandardScaler(), SVC(random_state=42, probability=True))\n",
        "\n",
        "# Initialize StratifiedKFold for cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_accuracy = cross_val_score(svm_pipeline, X, y, cv=skf, scoring='accuracy')\n",
        "cv_f1 = cross_val_score(svm_pipeline, X, y, cv=skf, scoring='f1_macro')\n",
        "cv_recall = cross_val_score(svm_pipeline, X, y, cv=skf, scoring='recall_macro')\n",
        "\n",
        "# Train the classifier on the scaled training data\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the probability scores of the test set\n",
        "y_scores = svm_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_scores)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Cross-Validated Accuracy:\", cv_accuracy.mean())\n",
        "print(\"Cross-Validated F1 Score:\", cv_f1.mean())\n",
        "print(\"Cross-Validated Recall:\", cv_recall.mean())\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Test F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"Test Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "runtime measurement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNYo9iIq_VX_",
        "outputId": "e81720de-681d-4c66-83bd-375a056521dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Fold Cross-validation completed in 0.61 seconds\n",
            "Average accuracy: 97.58%\n",
            "Training completed in 0.12 seconds\n",
            "Prediction completed in 0.02 seconds\n",
            "Test Accuracy: 0.9824561403508771\n",
            "Test F1 Score: 0.9811507936507937\n",
            "Test Recall: 0.9767441860465116\n",
            "ROC AUC Score: 0.99737962659679\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.97      1.00      0.99        71\n",
            "           M       1.00      0.95      0.98        43\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Total execution time: 0.91 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Start the total runtime timer\n",
        "total_start_time = time.time()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = y_train.squeeze()  # Using .squeeze() to convert DataFrame to Series\n",
        "y_test = y_test.squeeze()\n",
        "\n",
        "# Create a pipeline that includes scaling and the classifier\n",
        "svm_pipeline = make_pipeline(StandardScaler(), SVC(random_state=42, probability=True))\n",
        "\n",
        "# Initialize KFold for cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform K-Fold cross-validation\n",
        "start_time = time.time()  # Timer for K-Fold cross-validation\n",
        "cv_results = cross_val_score(svm_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "print(\"K-Fold Cross-validation completed in {:.2f} seconds\".format(time.time() - start_time))\n",
        "print(\"Average accuracy: {:.2f}%\".format(np.mean(cv_results) * 100))\n",
        "\n",
        "# Train the classifier on the scaled training data\n",
        "start_time = time.time()\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "print(\"Training completed in {:.2f} seconds\".format(time.time() - start_time))\n",
        "\n",
        "# Make predictions\n",
        "start_time = time.time()\n",
        "y_pred = svm_pipeline.predict(X_test)\n",
        "print(\"Prediction completed in {:.2f} seconds\".format(time.time() - start_time))\n",
        "\n",
        "# Calculate the ROC AUC Score\n",
        "y_scores = svm_pipeline.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_scores)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Test F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"Test Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# End the total runtime timer and print the total elapsed time\n",
        "total_elapsed_time = time.time() - total_start_time\n",
        "print(\"Total execution time: {:.2f} seconds\".format(total_elapsed_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5-fold validation score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHxFA2cX4Tvn",
        "outputId": "a12ebdb4-3cbb-4343-ec9a-a5065603fc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Fold Cross-validation completed in 0.62 seconds\n",
            "Average accuracy: 97.58%\n"
          ]
        }
      ],
      "source": [
        "# initialize KFold for cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform K-Fold cross-validation\n",
        "start_time = time.time()  # Timer for K-Fold cross-validation\n",
        "cv_results = cross_val_score(svm_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "print(\"K-Fold Cross-validation completed in {:.2f} seconds\".format(time.time() - start_time))\n",
        "print(\"Average accuracy: {:.2f}%\".format(np.mean(cv_results) * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "passive learning (random selection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random sample simulations (should be the same to ensure same initial model)\n",
        "random_seeds = [219+i for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize\n",
        "CV_train_all_passive = list()\n",
        "test_all_passive = list()\n",
        "\n",
        "for seed_idx, random_seed in enumerate(random_seeds):\n",
        "    np.random.seed(random_seed)\n",
        "    idices = list(range(y.shape[0]))\n",
        "    np.random.shuffle(idices)\n",
        "\n",
        "    # initialize\n",
        "    train_idices = idices[:int(len(idices)*0.2)]\n",
        "    test_idices = idices[int(len(idices)*0.2):]\n",
        "\n",
        "    CV_train_per_seed = list()\n",
        "    test_per_seed = list()\n",
        "\n",
        "    while (float(len(train_idices))/len(test_idices) < 0.5):\n",
        "        # cross-validate in the training set\n",
        "        clf = SVC(kernel='linear')\n",
        "        CV_train_per_seed.append(\n",
        "            np.mean(cross_val_score(clf, X.iloc[train_idices], y.iloc[train_idices], cv=5))\n",
        "        )\n",
        "        # update the clf to ensure it's re-initialized\n",
        "        clf = SVC(kernel='linear')\n",
        "        clf.fit(X.iloc[train_idices], y.iloc[train_idices])\n",
        "        y_pred = clf.predict(X.iloc[test_idices])\n",
        "        test_per_seed.append(accuracy_score(y.iloc[test_idices], y_pred))\n",
        "\n",
        "        # select the next point to mv from test to train\n",
        "        # for passive learning, just take the next random idx\n",
        "        train_idices = idices[:len(train_idices)+1]\n",
        "        test_idices = idices[len(train_idices):]\n",
        "\n",
        "    CV_train_all_passive.append(CV_train_per_seed)\n",
        "    test_all_passive.append(test_per_seed)\n",
        "\n",
        "CV_train_all_passive = np.array(CV_train_all_passive)\n",
        "test_all_passive = np.array(test_all_passive)\n",
        "CV_train_mean_passive = np.mean(CV_train_all_passive, axis=0)\n",
        "CV_train_std_passive = np.std(CV_train_all_passive, axis=0)\n",
        "test_mean_passive = np.mean(test_all_passive, axis=0)\n",
        "test_std_passive = np.std(test_all_passive, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "active learning (uncertainty sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize\n",
        "CV_train_all_active = list()\n",
        "test_all_active = list()\n",
        "\n",
        "for seed_idx, random_seed in enumerate(random_seeds):\n",
        "    np.random.seed(random_seed)\n",
        "    idices = list(range(y.shape[0]))\n",
        "    np.random.shuffle(idices)\n",
        "\n",
        "    # initialize\n",
        "    train_idices = idices[:int(len(idices)*0.2)]\n",
        "    test_idices = idices[int(len(idices)*0.2):]\n",
        "\n",
        "    CV_train_per_seed = list()\n",
        "    test_per_seed = list()\n",
        "\n",
        "    while (float(len(train_idices))/len(test_idices) < 0.5):\n",
        "        # cross-validate in the training set\n",
        "        clf = SVC(kernel='linear')\n",
        "        CV_train_per_seed.append(\n",
        "            np.mean(cross_val_score(clf, X.iloc[train_idices], y.iloc[train_idices], cv=5))\n",
        "        )\n",
        "        # update the clf to ensure it's re-initialized\n",
        "        clf = SVC(kernel='linear')\n",
        "        clf.fit(X.iloc[train_idices], y.iloc[train_idices])\n",
        "        y_pred = clf.predict(X.iloc[test_idices])\n",
        "        test_per_seed.append(accuracy_score(y.iloc[test_idices], y_pred))\n",
        "\n",
        "        # select the next point to mv from test to train\n",
        "        # for active learning, take the one closest to the decision boundary (for SVM)\n",
        "        # compute distances of each point to the decision boundary\n",
        "        distances = np.abs(np.dot(X.iloc[test_idices], clf.coef_[0]) + clf.intercept_) /\\\n",
        "        (np.linalg.norm(clf.coef_[0], ord=2, axis=0))\n",
        "        closest_index = np.argmin(distances)\n",
        "\n",
        "        # move the index from test to train\n",
        "        train_idices.append(test_idices[closest_index])\n",
        "        test_idices.pop(closest_index)\n",
        "\n",
        "    CV_train_all_active.append(CV_train_per_seed)\n",
        "    test_all_active.append(test_per_seed)\n",
        "\n",
        "CV_train_all_active = np.array(CV_train_all_active)\n",
        "test_all_active = np.array(test_all_active)\n",
        "CV_train_mean_active = np.mean(CV_train_all_active, axis=0)\n",
        "CV_train_std_active = np.std(CV_train_all_active, axis=0)\n",
        "test_mean_active = np.mean(test_all_active, axis=0)\n",
        "test_std_active = np.std(test_all_active, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "visualize the result for active learning against passive learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for plot in training set\n",
        "# for passive learning\n",
        "plt.errorbar(np.arange(CV_train_mean_passive.shape[0]),\n",
        "             CV_train_mean_passive,\n",
        "             yerr=CV_train_std_passive,\n",
        "             fmt='s',\n",
        "             color='steelblue',\n",
        "             ecolor='steelblue',\n",
        "             linestyle='--',\n",
        "             capsize=5,\n",
        "             label='CV_train_passive')\n",
        "\n",
        "\n",
        "\n",
        "# for active learning\n",
        "plt.errorbar(np.arange(CV_train_mean_active.shape[0]),\n",
        "             CV_train_mean_active,\n",
        "             yerr=CV_train_std_active,\n",
        "             fmt='s',\n",
        "             color='gold',\n",
        "             ecolor='gold',\n",
        "             linestyle='--',\n",
        "             capsize=5,\n",
        "             label='CV_train_active')\n",
        "\n",
        "\n",
        "# to display the legend\n",
        "plt.legend()\n",
        "\n",
        "# set up the characteristics of the plot\n",
        "\n",
        "plt.xlabel('Round Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Performance for Passive and Active Learning over training set in each round')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for plot in tesing set\n",
        "# for passive learning\n",
        "plt.errorbar(np.arange(test_mean_passive.shape[0]),\n",
        "             test_mean_passive,\n",
        "             yerr=test_std_passive,\n",
        "             fmt='s',\n",
        "             color='orange',\n",
        "             ecolor='orange',\n",
        "             linestyle='--',\n",
        "             capsize=5,\n",
        "             label='test_passive')\n",
        "\n",
        "# for active learning\n",
        "plt.errorbar(np.arange(test_mean_active.shape[0]),\n",
        "             test_mean_active,\n",
        "             yerr=test_std_active,\n",
        "             fmt='s',\n",
        "             color='green',\n",
        "             ecolor='green',\n",
        "             linestyle='--',\n",
        "             capsize=5,\n",
        "             label='test_active')\n",
        "\n",
        "# to display the legend\n",
        "plt.legend()\n",
        "\n",
        "# set up the characteristics of the plot\n",
        "\n",
        "plt.xlabel('Round Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Performance for Passive and Active Learning over testing set in each round')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
